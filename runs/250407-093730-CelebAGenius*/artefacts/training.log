2025-04-07 09:37:30,626 - INFO - Started logging to ./runs/250407-093730/artefacts/training.log
2025-04-07 09:37:30,626 - INFO - Config file: config.yaml
2025-04-07 09:37:30,626 - INFO - ==== Config file's contents ====
2025-04-07 09:37:30,626 - INFO - general:
2025-04-07 09:37:30,626 - INFO -   seed: 2024
2025-04-07 09:37:30,626 - INFO -   train: True
2025-04-07 09:37:30,626 - INFO -   dataset: celeba
2025-04-07 09:37:30,626 - INFO -   data_path: ./data/
2025-04-07 09:37:30,626 - INFO -   save_path: None
2025-04-07 09:37:30,626 - INFO - data:
2025-04-07 09:37:30,626 - INFO -   downsample_factor: 1
2025-04-07 09:37:30,626 - INFO -   resolution: [32, 32]
2025-04-07 09:37:30,626 - INFO -   traj_length: 1000
2025-04-07 09:37:30,626 - INFO - model:
2025-04-07 09:37:30,626 - INFO -   mlp_width_size: 24
2025-04-07 09:37:30,626 - INFO -   mlp_depth: 3
2025-04-07 09:37:30,626 - INFO -   activation: relu
2025-04-07 09:37:30,626 - INFO -   input_prev_data: False
2025-04-07 09:37:30,626 - INFO -   model_type: wsm-rnn
2025-04-07 09:37:30,626 - INFO -   nb_rnn_layers: 1
2025-04-07 09:37:30,626 - INFO -   weights_lim: None
2025-04-07 09:37:30,626 - INFO -   apply_tanh_uncertainty: False
2025-04-07 09:37:30,626 - INFO -   time_as_channel: False
2025-04-07 09:37:30,626 - INFO -   forcing_prob: 0.15
2025-04-07 09:37:30,626 - INFO -   noise_theta_init: None
2025-04-07 09:37:30,626 - INFO -   std_lower_bound: 0.0001
2025-04-07 09:37:30,626 - INFO - optimizer:
2025-04-07 09:37:30,626 - INFO -   init_lr: 1e-05
2025-04-07 09:37:30,626 - INFO -   gradients_lim: 1e-07
2025-04-07 09:37:30,627 - INFO -   on_plateau: {'factor': 0.5, 'min_scale': 0.01, 'patience': 20, 'cooldown': 0, 'rtol': 0.0001, 'accum_size': 50}
2025-04-07 09:37:30,627 - INFO - training:
2025-04-07 09:37:30,627 - INFO -   nb_epochs: 250
2025-04-07 09:37:30,627 - INFO -   batch_size: 1256
2025-04-07 09:37:30,627 - INFO -   print_every: 10
2025-04-07 09:37:30,627 - INFO -   checkpoint_every: 10
2025-04-07 09:37:30,627 - INFO -   nb_recons_loss_steps: None
2025-04-07 09:37:30,627 - INFO -   use_nll_loss: True
2025-04-07 09:37:30,627 - INFO -   inference_start: 300
2025-04-07 09:37:32,198 - INFO - Images shape: (1256, 1024, 3)
2025-04-07 09:37:32,198 - INFO - Labels shape: (1256,)
2025-04-07 09:37:32,198 - INFO - Seq length: 1024
2025-04-07 09:37:32,198 - INFO - Data size: 3
2025-04-07 09:37:32,200 - INFO - Min/Max in the dataset: (-1.0, 1.0)
2025-04-07 09:37:32,200 - INFO - Number of batches:
2025-04-07 09:37:32,200 - INFO -   - Train: 130
2025-04-07 09:37:32,200 - INFO -   - Test: 16
2025-04-07 09:37:33,643 - INFO - No model found in run folder. Training from scratch.
2025-04-07 09:37:33,643 - INFO - 

=== Beginning training ... ===
2025-04-07 09:37:33,643 - INFO -   - Number of epochs: 250
2025-04-07 09:37:33,644 - INFO -   - Number of batches: 130
2025-04-07 09:37:33,644 - INFO -   - Total number of GD steps: 32500
2025-04-07 09:38:53,272 - INFO - Epoch    0/ 250     Train Loss   -Mean: 64899.023438,   -Median: -0.109199,   -Latest: -0.161694
2025-04-07 09:38:53,298 - INFO - Best model saved ...
2025-04-07 09:40:11,112 - INFO - Epoch    1/ 250     Train Loss   -Mean: -0.219212,   -Median: -0.222864,   -Latest: -0.259884
2025-04-07 09:41:28,827 - INFO - Epoch    2/ 250     Train Loss   -Mean: -0.269587,   -Median: -0.272869,   -Latest: -0.282643
2025-04-07 09:42:46,422 - INFO - Epoch    3/ 250     Train Loss   -Mean: -0.295314,   -Median: -0.296973,   -Latest: -0.301510
2025-04-07 09:51:50,066 - INFO - Epoch   10/ 250     Train Loss   -Mean: -0.346770,   -Median: -0.347099,   -Latest: -0.349394
2025-04-07 09:51:50,118 - INFO - Best model saved ...
2025-04-07 10:04:47,444 - INFO - Epoch   20/ 250     Train Loss   -Mean: -0.411101,   -Median: -0.410567,   -Latest: -0.430055
2025-04-07 10:04:47,507 - INFO - Best model saved ...
2025-04-07 10:17:45,732 - INFO - Epoch   30/ 250     Train Loss   -Mean: -0.453599,   -Median: -0.455195,   -Latest: -0.452639
2025-04-07 10:17:45,799 - INFO - Best model saved ...
2025-04-07 10:30:42,807 - INFO - Epoch   40/ 250     Train Loss   -Mean: -0.478612,   -Median: -0.480019,   -Latest: -0.454083
2025-04-07 10:30:42,887 - INFO - Best model saved ...
2025-04-07 10:43:40,371 - INFO - Epoch   50/ 250     Train Loss   -Mean: -0.496127,   -Median: -0.496437,   -Latest: -0.519746
2025-04-07 10:43:40,453 - INFO - Best model saved ...
2025-04-07 10:56:39,525 - INFO - Epoch   60/ 250     Train Loss   -Mean: -0.499897,   -Median: -0.502199,   -Latest: -0.490918
2025-04-07 10:56:39,614 - INFO - Best model saved ...
2025-04-07 11:09:35,674 - INFO - Epoch   70/ 250     Train Loss   -Mean: -0.518193,   -Median: -0.519111,   -Latest: -0.531632
2025-04-07 11:09:35,789 - INFO - Best model saved ...
2025-04-07 11:22:33,778 - INFO - Epoch   80/ 250     Train Loss   -Mean: -0.522312,   -Median: -0.523173,   -Latest: -0.557568
2025-04-07 11:22:33,891 - INFO - Best model saved ...
2025-04-07 11:35:34,376 - INFO - Epoch   90/ 250     Train Loss   -Mean: -0.548084,   -Median: -0.549504,   -Latest: -0.544229
2025-04-07 11:35:34,490 - INFO - Best model saved ...
2025-04-07 11:48:33,404 - INFO - Epoch  100/ 250     Train Loss   -Mean: -0.559400,   -Median: -0.559793,   -Latest: -0.563311
2025-04-07 11:48:33,531 - INFO - Best model saved ...
2025-04-07 12:01:30,384 - INFO - Epoch  110/ 250     Train Loss   -Mean: -0.557912,   -Median: -0.559303,   -Latest: -0.551554
2025-04-07 12:14:27,093 - INFO - Epoch  120/ 250     Train Loss   -Mean: -0.567896,   -Median: -0.567325,   -Latest: -0.569237
2025-04-07 12:14:27,237 - INFO - Best model saved ...
2025-04-07 12:27:23,885 - INFO - Epoch  130/ 250     Train Loss   -Mean: -0.564531,   -Median: -0.564093,   -Latest: -0.562451
2025-04-07 12:40:22,405 - INFO - Epoch  140/ 250     Train Loss   -Mean: -0.592854,   -Median: -0.593987,   -Latest: -0.586855
2025-04-07 12:40:22,564 - INFO - Best model saved ...
2025-04-07 12:53:20,891 - INFO - Epoch  150/ 250     Train Loss   -Mean: -0.590634,   -Median: -0.590902,   -Latest: -0.578168
2025-04-07 13:06:22,865 - INFO - Epoch  160/ 250     Train Loss   -Mean: -0.602650,   -Median: -0.602435,   -Latest: -0.613869
2025-04-07 13:06:23,047 - INFO - Best model saved ...
2025-04-07 13:19:21,637 - INFO - Epoch  170/ 250     Train Loss   -Mean: -0.607521,   -Median: -0.607545,   -Latest: -0.615095
2025-04-07 13:19:21,822 - INFO - Best model saved ...
2025-04-07 13:32:23,478 - INFO - Epoch  180/ 250     Train Loss   -Mean: -0.609109,   -Median: -0.609281,   -Latest: -0.627718
2025-04-07 13:32:23,684 - INFO - Best model saved ...
2025-04-07 13:45:22,866 - INFO - Epoch  190/ 250     Train Loss   -Mean: -0.612121,   -Median: -0.611729,   -Latest: -0.602896
2025-04-07 13:45:23,076 - INFO - Best model saved ...
2025-04-07 13:58:24,490 - INFO - Epoch  200/ 250     Train Loss   -Mean: -0.612916,   -Median: -0.613091,   -Latest: -0.620775
2025-04-07 13:58:24,704 - INFO - Best model saved ...
2025-04-07 14:11:24,082 - INFO - Epoch  210/ 250     Train Loss   -Mean: -0.614755,   -Median: -0.614426,   -Latest: -0.619380
2025-04-07 14:11:24,313 - INFO - Best model saved ...
2025-04-07 14:24:23,243 - INFO - Epoch  220/ 250     Train Loss   -Mean: -0.614889,   -Median: -0.615094,   -Latest: -0.615729
2025-04-07 14:24:23,472 - INFO - Best model saved ...
2025-04-07 14:37:21,948 - INFO - Epoch  230/ 250     Train Loss   -Mean: -0.615425,   -Median: -0.615248,   -Latest: -0.609677
2025-04-07 14:37:22,186 - INFO - Best model saved ...
2025-04-07 14:50:22,569 - INFO - Epoch  240/ 250     Train Loss   -Mean: -0.615981,   -Median: -0.615108,   -Latest: -0.610741
2025-04-07 15:02:03,681 - INFO - Epoch  249/ 250     Train Loss   -Mean: 1.037208,   -Median: -0.616351,   -Latest: -0.605405
2025-04-07 15:02:03,925 - INFO - Best model saved ...
2025-04-07 15:02:03,926 - INFO - 
Training complete. Total time: 5 hours 24 mins 30 secs
2025-04-07 15:02:03,926 - INFO - No losses found in the nohup.log file
2025-04-07 15:02:12,694 - INFO - Evaluation of MSE the test set:
2025-04-07 15:02:12,695 - INFO -     - Mean : 0.129256
2025-04-07 15:02:12,695 - INFO -     - Median : 0.129483
2025-04-07 15:02:12,695 - INFO -     - Min : 0.126784
2025-04-07 15:02:13,463 - INFO - Min/Max Uncertainty: 0.023, 1.363
2025-04-07 15:02:13,469 - INFO - Min/Max Uncertainty: 0.023, 1.363
2025-04-07 15:02:13,475 - INFO - Min/Max Uncertainty: 0.023, 1.363
2025-04-07 15:02:13,480 - INFO - Min/Max Uncertainty: 0.023, 1.363
2025-04-07 15:02:13,486 - INFO - Min/Max Uncertainty: 0.023, 1.363
2025-04-07 15:02:13,491 - INFO - Min/Max Uncertainty: 0.023, 1.363
2025-04-07 15:02:13,497 - INFO - Min/Max Uncertainty: 0.023, 1.363
2025-04-07 15:02:13,501 - INFO - Min/Max Uncertainty: 0.023, 1.363
2025-04-07 15:02:13,507 - INFO - Min/Max Uncertainty: 0.023, 1.363
2025-04-07 15:02:13,512 - INFO - Min/Max Uncertainty: 0.023, 1.363
2025-04-07 15:02:13,517 - INFO - Min/Max Uncertainty: 0.023, 1.363
2025-04-07 15:02:13,522 - INFO - Min/Max Uncertainty: 0.023, 1.363
2025-04-07 15:02:13,526 - INFO - Min/Max Uncertainty: 0.023, 1.363
2025-04-07 15:02:13,532 - INFO - Min/Max Uncertainty: 0.023, 1.363
2025-04-07 15:02:13,537 - INFO - Min/Max Uncertainty: 0.023, 1.363
2025-04-07 15:02:13,542 - INFO - Min/Max Uncertainty: 0.023, 1.363
