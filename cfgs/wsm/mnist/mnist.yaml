# General settings
general:
  seed: 2028
  classification: False
  train: True
  dataset: "mnist"
  data_path: "./data/"
  save_path: null

# Data hyperparameters
data:
  downsample_factor: 1
  normalize: False

# Model hyperparameters
model:
  root_width_size: 24
  root_depth: 3
  root_activation: "relu"
  root_final_activation: "tanh"
  init_state_layers: null
  input_prev_data: False
  model_type: "wsm"
  nb_rnn_layers: 1
  weights_lim: 5.0e-1
  time_as_channel: False
  forcing_prob: 0.15
  noise_theta_init: null
  std_lower_bound: 5.0e-1

# Optimizer hyperparameters
optimizer:
  init_lr: 1.0e-4
  gradients_lim: 1.0e-7
  on_plateau:
    factor: 0.5
    min_scale: 1.0e-2
    patience: 20
    cooldown: 0
    rtol: 1.0e-4
    accum_size: 50

# Training/Inference configurations
training:
  nb_epochs: 200
  batch_size: 640
  autoregressive: True
  print_every: 10
  save_every: 10
  valid_every: 10
  stochastic: False
  val_criterion: "mse"
  nb_recons_loss_steps: 400
  use_nll_loss: True
  inference_start: 300
  smooth_inference: True
