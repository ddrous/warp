# Base configuration file

# General settings
general:
  seed: 2024
  train: True
  dataset: "mnist"  # Options: mnist, cifar, trends, mnist_fashion, lorentz, dynamics
  data_folder: "./data"

# Data hyperparameters (dependent on the dataset)
data:
  downsample_factor: 2
  resolution: [32, 342]         # For celebA
  traj_length: 1000

# Model hyperparameters
model:
  mlp_width_size: 24
  mlp_depth: 3
  activation: "relu"
  model_type: "wsm-rnn"
  nb_rnn_layers: 1
  weights_lim: null
  apply_tanh_uncertainty: True
  time_as_channel: False
  forcing_prob: 0.15
  input_prev_data: True
  noisy_theta_init: False

# Optimizer hyperparameters
optimizer:
  init_lr: 1.0e-5
  gradients_lim: 1.0e-7
  on_plateau:
    factor: 0.5
    min_scale: 1.0e-2
    patience: 20
    cooldown: 0
    rtol: 1.0e-4
    accum_size: 50

# Training/Inference hyperparameters
training:
  nb_epochs: 500
  batch_size: 6400
  print_every: 100
  checkpoint_every: 100
  nb_recons_loss_steps: 400
  use_nll_loss: True
  inference_start: 15
